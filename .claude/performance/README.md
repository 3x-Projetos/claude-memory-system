# Performance Tracking System (M009)

**Prop√≥sito**: Metrificar e comparar performance de diferentes agentes e modelos para decis√µes data-driven sobre qual usar em cada contexto.

---

## Estrutura

```
.claude/performance/
‚îú‚îÄ‚îÄ README.md                          # Este arquivo
‚îú‚îÄ‚îÄ TEMPLATE-performance-profile.md    # Template para novos profiles
‚îú‚îÄ‚îÄ profiles/
‚îÇ   ‚îú‚îÄ‚îÄ claude-sonnet-4.5.md          # Profile por modelo
‚îÇ   ‚îú‚îÄ‚îÄ claude-haiku.md
‚îÇ   ‚îú‚îÄ‚îÄ gemini-1.5-pro.md
‚îÇ   ‚îú‚îÄ‚îÄ deepseek-coder-33b.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ comparisons/
‚îÇ   ‚îî‚îÄ‚îÄ 2025.11.md                    # An√°lises comparativas mensais
‚îî‚îÄ‚îÄ context-analysis/
    ‚îî‚îÄ‚îÄ prompt-optimization.md         # Insights de otimiza√ß√£o de prompts
```

---

## M√©tricas Coletadas

### Quantitativas (Autom√°ticas)
- **Tokens/session**: M√©dia, mediana, P95
- **Context window usage**: % utilizado da janela dispon√≠vel
- **Prompt length distribution**: Histograma de tamanhos de prompt
- **Output/Input ratio**: Efici√™ncia de gera√ß√£o
- **Latency**: Tempo m√©dio de resposta (quando aplic√°vel)
- **Cost**: Custo relativo ($ to $$$$)
- **Efficiency**: Tokens economizados com framework vs sem
- **Volume**: Linhas de c√≥digo, arquivos modificados
- **Context limit hits**: Quantas vezes atingiu limite de contexto

### Qualitativas (Inferidas + Opcionalmente Perguntadas)
- **Task type**: Architecture, Code Gen, Refactoring, Debugging, Docs, Research
- **Specialization**: Tecnologias espec√≠ficas (Python, JS, Rust, etc)
- **Quality rating**: 1-5 stars (usu√°rio opcionalmente avalia)
- **Success rate**: Completou tarefa? (yes/partial/no)
- **Pattern detection**: Padr√µes de uso cross-domain
- **Context efficiency**: Qualidade vs tamanho de contexto usado

### Context Window Metrics (Foco Principal)
- **Window utilization**: % m√©dio, peak, frequency of hitting limits
- **Prompt optimization**: Optimal prompt length range (correla√ß√£o com qualidade)
- **Context quality correlation**: Sweet spot identification
- **Model-specific patterns**: Como cada modelo usa sua janela
- **Framework efficiency**: ROI da hierarquia de mem√≥ria

---

## Workflow de Coleta

### Durante `/end`

**Passo 4: Coletar Performance Metrics**

1. **Auto-detectar** (zero friction):
   - Modelo usado (j√° implementado em Passo 1)
   - Tokens: budget, usados, % utilizado
   - Duration: inferir de session timestamps
   - Files: git diff --stat
   - Technologies: file extensions + imports
   - Task type: arquivos modificados + comandos
   - Project: rastreado em M008

2. **Perguntar (opcional - pul√°vel)**:
   ```
   üìä Avalia√ß√£o de Performance (Enter para pular):

   1. Qualidade: ‚≠ê [1-5, Enter=auto]
   2. Completou? [yes/partial/no, Enter=yes]
   3. Categoria: [architecture/code/etc, Enter=auto]
   ```

3. **Registrar**:
   - Se profile n√£o existe: criar de template
   - Append session entry
   - Update stats agregados

4. **No log di√°rio**: Incluir se√ß√£o "Performance Metrics"

---

## An√°lise e Insights

### Mensal (via `/aggregate month`)
- Re-calcular stats agregados de cada profile
- Gerar an√°lise comparativa (comparisons/YYYY.MM.md)
- Identificar sweet spots de contexto por task type
- Atualizar context optimization insights

### Insights Gerados

**Context Optimization** (exemplo):
```
üìä Descoberta: Tarefas de architecture t√™m qualidade 4.8/5
quando contexto usado √© 50-70%, mas cai para 4.1/5 quando >85%.

Recomenda√ß√£o: Carregar contexto rico mas evitar overload.
Framework atual: Excelente (sweet spot 40-60%).
```

**Model Selection** (exemplo):
```
üí° Sugest√£o: Tarefa detectada como "refactor simples".
Sonnet pode ser overkill.

Considere Haiku:
- 20x mais r√°pido
- 75% mais barato
- Qualidade suficiente para refactors simples (4.2/5 hist√≥rico)
```

---

## Benef√≠cios Esperados

1. **Economia de tokens**: Escolher modelo right-sized
2. **Melhor qualidade**: Usar modelo especializado quando importa
3. **Prompt optimization**: Identificar comprimento √≥timo
4. **Context efficiency**: Saber quando mais contexto ajuda vs atrapalha
5. **Comparative analysis**: Data para decidir qual modelo usar
6. **Continuous improvement**: Tracking de tend√™ncias
7. **ROI do framework**: Quantificar benef√≠cio da hierarquia
8. **Multi-agent orchestration**: Dados para routing inteligente (futuro)

---

## Fases de Implementa√ß√£o

### ‚úÖ Fase 1 (Imediato)
- Estrutura de diret√≥rios criada
- Template de profile criado
- Coleta integrada no `/end`
- Auto-detection implementada
- Perguntas opcionais adicionadas

### üìã Fase 2 (Ap√≥s 2-3 semanas)
- An√°lise comparativa mensal
- Script de agrega√ß√£o
- Identificar sweet spots de contexto
- Gerar comparisons/YYYY.MM.md

### üìã Fase 3 (Ap√≥s 1-2 meses)
- Recomenda√ß√µes autom√°ticas no `/end`
- Sugest√µes de modelo alternativo
- Alertas de context overload

### üìã Fase 4 (Futuro)
- Multi-agent routing autom√°tico
- Sistema escolhe modelo baseado em task + hist√≥rico
- Hybrid approach: Claude (architecture) + DeepSeek (code) + Gemini (research)

---

## Princ√≠pios

1. **Auto-detection first**: Minimizar friction (perguntas opcionais)
2. **Continuous collection**: Dados coletados a cada sess√£o
3. **Model-agnostic**: Funciona com qualquer agente/modelo
4. **Data-driven**: Decis√µes baseadas em dados reais, n√£o emp√≠ricos
5. **Context-aware**: Foco especial em otimiza√ß√£o de janela de contexto
6. **Privacy**: Todos os dados ficam locais (n√£o compartilhados)

---

## Como Usar

### Para o Usu√°rio
1. Continue usando `/end` normalmente
2. (Opcional) Responda perguntas de qualidade se quiser
3. Sistema coleta dados automaticamente
4. Use `/aggregate month` mensalmente para an√°lises

### Para Claude (Agente)
1. Ao executar `/end`, siga Passo 4 (Coletar Performance Metrics)
2. Auto-detecte tudo que puder
3. Pergunte qualidade/success apenas se usu√°rio quiser dados precisos
4. Registre no profile do modelo
5. Inclua Performance Metrics no log di√°rio
6. Ao executar `/aggregate month`, analise profiles e gere insights

---

## Notas

- **Context window metrics** foram adicionados por solicita√ß√£o expl√≠cita do usu√°rio
- Sistema combina m√©tricas de contexto com qualidade/custo para insights poderosos
- Permite otimizar prompts baseado em dados reais de uso
- Framework de mem√≥ria hier√°rquica j√° economiza tokens - agora medimos quanto

---

*Parte do M009: Agent Performance Tracking & Context Window Metrics*
*Sistema de Mem√≥ria Hier√°rquica v2.1+*
*Estabelecido: 2025-11-16*
